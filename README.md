# AI Dubbing Project

A Python-based application that uses artificial intelligence technology to automatically dub YouTube videos into different languages.

## ğŸŒŸ Features

- Download YouTube videos directly from URL  
- Extract audio and transcribe speech to text  
- Translate text into the target language  
- Generate natural-sounding speech in the target language  
- Merge video with newly generated audio  
- Multiple TTS engine options (Bark, Coqui, Google TTS)  
- Voice cloning feature (dub using a reference voice)  
- Comprehensive logging system  

## ğŸ”Š Voice Cloning

AI Dubbing offers the ability to dub in different languages using your own voice or any reference voice:

```bash
python main.py "https://www.youtube.com/watch?v=YOUTUBE_ID" \
  --source en \
  --target tr \
  --tts voice_clone \
  --reference-audio "path_to_your_reference_audio.wav"
```

### Overview

The Voice Cloning feature allows you to clone a voice from a reference audio sample and use it to generate speech in multiple languages. This creates a more personalized and consistent dubbing experience.

### How It Works

The voice cloning system uses two approaches:

1. **Primary Method (XTTS)**: When possible, the system uses the XTTS v2 model from the Coqui TTS library for high-quality voice cloning. This model can generate speech in multiple languages while preserving the characteristics of the reference voice.

2. **Fallback Method (gTTS)**: If the XTTS model cannot be loaded (due to incompatibility with PyTorch 2.6+ or other issues), the system automatically falls back to Google Text-to-Speech (gTTS) to generate speech in the target language.

### Record Your Own Voice

This tool also supports recording your own voice as a reference sample:

```bash
python main.py "https://www.youtube.com/watch?v=YOUTUBE_ID" \
  --source en \
  --target tr \
  --tts voice_clone \
  --record \
  --record-duration 10
```

This will prompt you to speak for 10 seconds to generate a reference sample, which will then be used for voice cloning.

### Voice Cloning Test

You can test the voice cloning feature directly using the provided test script:

```bash
python test_voice_cloner.py
```

This will generate sample audio files in multiple languages using the voice cloning feature.

### Supported Languages

The voice cloning feature supports the following languages:

- English (en)  
- French (fr)  
- Turkish (tr)  
- Spanish (es)  
- Italian (it)  
- German (de)  
- Portuguese (pt)  
- Polish (pl)  
- Russian (ru)  
- Dutch (nl)  
- Czech (cs)  
- Arabic (ar)  
- Chinese (zh)  
- Japanese (ja)  
- Korean (ko)  
- Hungarian (hu)  

### Troubleshooting

#### PyTorch 2.6+ Compatibility Issues

If you're using PyTorch 2.6 or newer, you may encounter compatibility issues with the XTTS model due to the `weights_only` parameter in `torch.load()`. The system is designed to handle this automatically and will fall back to gTTS, but if you want to use XTTS directly, try the following:

1. Set environment variable:
   ```bash
   export TORCH_FULL_LOAD=1
   ```

2. Add safe globals for PyTorch 2.6+:
   ```python
   from TTS.tts.configs.xtts_config import XttsConfig
   from TTS.tts.models.xtts import XttsAudioConfig
   import torch
   torch.serialization.add_safe_globals([XttsConfig, XttsAudioConfig])
   ```

#### Low Voice Cloning Quality

For the best voice cloning results:

1. Use a high-quality reference audio sample  
2. Ensure the reference audio is clear with minimal background noise  
3. Reference audio should be at least 3 seconds long  
4. Record in a quiet environment with good acoustic conditions  
5. Use a good quality microphone  

### Output Files

When using voice cloning, the system generates the following files:

- `outputs/dubbed_audio.wav`: The audio generated with the cloned voice  
- `outputs/dubbed_video.mp4`: Final video dubbed with the cloned voice  
- `outputs/samples/test_reference_audio.wav`: The reference audio sample (if recorded)  

## ğŸ› ï¸ Technologies Used

- **Video Processing**: `pytube`, `ffmpeg`, `moviepy`  
- **Speech Recognition**: OpenAI Whisper (open-source)  
- **Translation**: Google Translate (unofficial), OpenAI GPT-3.5  
- **Text-to-Speech (TTS)**: Bark, Coqui TTS, Google TTS, XTTS (voice cloning)  
- **Logging**: Python's built-in logging module  

## ğŸ“‹ Requirements

- Python 3.10 or higher  
- ffmpeg installed on your system  
- Required Python packages (see `requirements.txt`)  
- For voice cloning:  
  - TTS library (`pip install TTS`)  
  - gTTS library (`pip install gtts`)  
  - Reference audio file (.wav format, at least 3 seconds long)  

## ğŸ”§ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/CotNeo/ai_dub.git
   cd ai_dub
   ```

2. Create a virtual environment (recommended):
   ```bash
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate
   ```

3. Install required dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Install ffmpeg:
   - **macOS**: `brew install ffmpeg`
   - **Ubuntu/Debian**: `sudo apt-get install ffmpeg`
   - **Windows**: Download from [ffmpeg.org](https://ffmpeg.org/download.html) and add to PATH

5. Set API keys (optional):
   ```bash
   cp config/api_keys.py.example config/api_keys.py
   ```
   Edit the created `config/api_keys.py` file to add your own API keys.

   Alternatively, set API keys as environment variables:
   ```bash
   export OPENAI_API_KEY="your_openai_api_key"
   ```

6. (Optional) If using OpenAI services, configure your API keys in `config/settings.py`

## ğŸš€ Usage

### Basic Usage

Run the application with a YouTube URL:

```bash
python main.py https://www.youtube.com/watch?v=example_id
```

### Advanced Options

Specify source and target languages:

```bash
python main.py https://www.youtube.com/watch?v=example_id --source en --target tr
```

Available parameters:
- `--source` or `-s`: Source language code (default: en)  
- `--target` or `-t`: Target language code (default: tr)  
- `--tts`: TTS engine option (default: gtts, other options: bark, coqui, voice_clone)  
- `--reference-audio`: Reference audio file for voice cloning (used with voice_clone)  
- `--record`: Record reference audio (used with voice_clone)  
- `--record-duration`: Duration of recording in seconds (default: 10)  

## ğŸ§¹ Project Structure

```
ai_dub/
â”œâ”€â”€ main.py                       # Main application entry point
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py               # Configuration settings
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ logger.py                 # Logging utility
â”‚   â”œâ”€â”€ downloader.py             # YouTube video downloader
â”‚   â”œâ”€â”€ audio_extractor.py        # Audio extractor
â”‚   â”œâ”€â”€ transcriber.py            # Speech-to-text
â”‚   â”œâ”€â”€ translator.py             # Text translation
â”‚   â”œâ”€â”€ tts.py                    # Text-to-speech
â”‚   â”œâ”€â”€ voice_cloner.py           # Voice cloning module
â”‚   â””â”€â”€ video_merger.py           # Merge video and audio
â”œâ”€â”€ outputs/                      # Output and temporary files
â”œâ”€â”€ logs/                         # Log files
â”œâ”€â”€ requirements.txt              # Project dependencies
â””â”€â”€ README.md                     # Project documentation
```

## âš™ï¸ Customization

You can customize the application by editing the `config/settings.py` file:

- Change default languages  
- Select different TTS engines  
- Configure model parameters  
- Set output file paths  

## ğŸ¤ Contributing

Contributions are welcome! Feel free to submit a Pull Request.

## ğŸ“œ License

This project is open-source and available under the [MIT License](LICENSE).

## ğŸ™ Thanks

- [OpenAI Whisper](https://github.com/openai/whisper) for speech recognition  
- [Bark](https://github.com/suno-ai/bark) and [Coqui TTS](https://github.com/coqui-ai/TTS) for text-to-speech capabilities  
- [pytube](https://github.com/pytube/pytube) for YouTube downloading functionality  
- [XTTS](https://coqui.ai/blog/tts/xtts-v2-improving-zero-shot-cross-lingual-text-to-speech) for voice cloning  
- [gTTS](https://github.com/pndurette/gTTS) as a fallback TTS option  

---

## ğŸ“ Support

If you have any questions or encounter issues, please open an issue in this repository.

## ğŸ§‘â€ğŸ’» Developer

This project is developed by [CotNeo](https://github.com/CotNeo).



# AI Dublaj Projesi

Yapay zeka teknolojisini kullanarak YouTube videolarÄ±nÄ± farklÄ± dillere otomatik olarak dublaj yapmanÄ±zÄ± saÄŸlayan Python tabanlÄ± bir uygulama.

## ğŸŒŸ Ã–zellikler

- YouTube videolarÄ±nÄ± URL'den doÄŸrudan indirme
- Ses Ã§Ä±karma ve konuÅŸmayÄ± metne dÃ¶nÃ¼ÅŸtÃ¼rme
- Metni hedef dile Ã§evirme
- Hedef dilde doÄŸal sesli konuÅŸma oluÅŸturma
- Videoyu yeni oluÅŸturulan sesle birleÅŸtirme
- Birden fazla TTS motor seÃ§eneÄŸi (Bark, Coqui, Google TTS)
- Ses klonlama Ã¶zelliÄŸi (referans ses ile dublaj)
- KapsamlÄ± gÃ¼nlÃ¼k (log) sistemi

## ğŸ”Š Ses Klonlama

AI Dublaj, kendi sesinizi veya herhangi bir referans sesi kullanarak, farklÄ± dillerde dublaj yapabilme Ã¶zelliÄŸi sunar:

```bash
python main.py "https://www.youtube.com/watch?v=YOUTUBE_ID" \
  --source en \
  --target tr \
  --tts voice_clone \
  --reference-audio "referans_sesinizin_yolu.wav"
```

### Genel BakÄ±ÅŸ

Ses Klonlama Ã¶zelliÄŸi, bir referans ses Ã¶rneÄŸinden sesi klonlamanÄ±za ve bu sesi birden fazla dilde konuÅŸma oluÅŸturmak iÃ§in kullanmanÄ±za olanak tanÄ±r. Bu, daha kiÅŸiselleÅŸtirilmiÅŸ ve tutarlÄ± bir dublaj deneyimi yaratÄ±r.

### NasÄ±l Ã‡alÄ±ÅŸÄ±r

Ses klonlama sistemi iki yaklaÅŸÄ±m kullanÄ±r:

1. **Birincil YÃ¶ntem (XTTS)**: MÃ¼mkÃ¼n olduÄŸunda, sistem yÃ¼ksek kaliteli ses klonlama iÃ§in Coqui TTS kÃ¼tÃ¼phanesinin XTTS v2 modelini kullanÄ±r. Bu model, referans sesin karakteristik Ã¶zelliklerini korurken birden fazla dilde konuÅŸma oluÅŸturabilir.

2. **Yedek YÃ¶ntem (gTTS)**: XTTS modeli yÃ¼klenemezse (PyTorch 2.6+ ile uyumluluk sorunlarÄ± veya baÅŸka nedenlerden dolayÄ±), sistem otomatik olarak hedef dilde konuÅŸma oluÅŸturmak iÃ§in Google Text-to-Speech (gTTS) kullanÄ±mÄ±na geÃ§er.

### Kendi Sesinizi Kaydedin

Bu araÃ§, referans Ã¶rnek olarak kendi sesinizi kaydetmeyi de destekler:

```bash
python main.py "https://www.youtube.com/watch?v=YOUTUBE_ID" \
  --source en \
  --target tr \
  --tts voice_clone \
  --record \
  --record-duration 10
```

Bu, bir referans ses Ã¶rneÄŸi oluÅŸturmak iÃ§in 10 saniye boyunca konuÅŸmanÄ±zÄ± isteyecek ve ardÄ±ndan bu Ã¶rnek ses klonlama iÃ§in kullanÄ±lacaktÄ±r.

### Ses Klonlama Testi

Ses klonlama Ã¶zelliÄŸini doÄŸrudan saÄŸlanan test betiÄŸi kullanarak test edebilirsiniz:

```bash
python test_voice_cloner.py
```

Bu, ses klonlama Ã¶zelliÄŸini kullanarak birden fazla dilde Ã¶rnek ses dosyalarÄ± oluÅŸturacaktÄ±r.

### Desteklenen Diller

Ses klonlama Ã¶zelliÄŸi aÅŸaÄŸÄ±daki dilleri destekler:

- Ä°ngilizce (en)
- FransÄ±zca (fr)
- TÃ¼rkÃ§e (tr)
- Ä°spanyolca (es)
- Ä°talyanca (it)
- Almanca (de)
- Portekizce (pt)
- LehÃ§e (pl)
- RusÃ§a (ru)
- Hollandaca (nl)
- Ã‡ekÃ§e (cs)
- ArapÃ§a (ar)
- Ã‡ince (zh)
- Japonca (ja)
- Korece (ko)
- Macarca (hu)

### Sorun Giderme

#### PyTorch 2.6+ Uyumluluk SorunlarÄ±

PyTorch 2.6 veya daha yeni bir sÃ¼rÃ¼m kullanÄ±yorsanÄ±z, `torch.load()` fonksiyonundaki `weights_only` parametresi nedeniyle XTTS modeliyle uyumluluk sorunlarÄ± yaÅŸayabilirsiniz. Sistem bunu otomatik olarak ele almak iÃ§in tasarlanmÄ±ÅŸtÄ±r ve gTTS'ye geri dÃ¶ner, ancak XTTS'i doÄŸrudan kullanmak istiyorsanÄ±z ÅŸunlarÄ± deneyebilirsiniz:

1. Ortam deÄŸiÅŸkeni ayarlama:
   ```bash
   export TORCH_FULL_LOAD=1
   ```

2. PyTorch 2.6+ iÃ§in gÃ¼venli globalleri ekleme:
   ```python
   from TTS.tts.configs.xtts_config import XttsConfig
   from TTS.tts.models.xtts import XttsAudioConfig
   import torch
   torch.serialization.add_safe_globals([XttsConfig, XttsAudioConfig])
   ```

#### DÃ¼ÅŸÃ¼k Ses Klonlama Kalitesi

En iyi ses klonlama sonuÃ§larÄ± iÃ§in:

1. YÃ¼ksek kaliteli bir referans ses Ã¶rneÄŸi kullanÄ±n
2. Referans sesin net olduÄŸundan ve minimum arka plan gÃ¼rÃ¼ltÃ¼sÃ¼ iÃ§erdiÄŸinden emin olun
3. Referans ses en az 3 saniye uzunluÄŸunda olmalÄ±dÄ±r
4. Ä°yi akustik Ã¶zelliklere sahip sessiz bir ortamda kaydedin
5. Ä°yi kalitede bir mikrofon kullanÄ±n

### Ã‡Ä±ktÄ± DosyalarÄ±

Ses klonlama kullanÄ±ldÄ±ÄŸÄ±nda, sistem aÅŸaÄŸÄ±daki dosyalarÄ± oluÅŸturur:

- `outputs/dubbed_audio.wav`: KlonlanmÄ±ÅŸ sesle oluÅŸturulan ses
- `outputs/dubbed_video.mp4`: KlonlanmÄ±ÅŸ sesle orjinal videonun Ã¼zerine dublaj yapÄ±lmÄ±ÅŸ son video
- `outputs/samples/test_reference_audio.wav`: Referans ses Ã¶rneÄŸi (kayÄ±t yoluyla oluÅŸturulmuÅŸsa)

## ğŸ› ï¸ KullanÄ±lan Teknolojiler

- **Video Ä°ÅŸleme**: `pytube`, `ffmpeg`, `moviepy`
- **KonuÅŸma TanÄ±ma**: OpenAI Whisper (aÃ§Ä±k kaynak)
- **Ã‡eviri**: Google Translate (gayri resmi), OpenAI GPT-3.5
- **Metinden Sese DÃ¶nÃ¼ÅŸtÃ¼rme**: Bark, Coqui TTS, Google TTS, XTTS (ses klonlama)
- **GÃ¼nlÃ¼k Tutma**: Python'un dahili logging modÃ¼lÃ¼

## ğŸ“‹ Gereksinimler

- Python 3.10 veya daha yÃ¼ksek
- Sisteminizde kurulu ffmpeg
- Gerekli Python paketleri (bkz. `requirements.txt`)
- Ses klonlama iÃ§in:
  - TTS kÃ¼tÃ¼phanesi (`pip install TTS`)
  - gTTS kÃ¼tÃ¼phanesi (`pip install gtts`)
  - Referans ses dosyasÄ± (.wav formatÄ±nda, en az 3 saniye uzunluÄŸunda)

## ğŸ”§ Kurulum

1. Depoyu klonlayÄ±n:
   ```bash
   git clone https://github.com/CotNeo/ai_dub.git
   cd ai_dub
   ```

2. Sanal ortam oluÅŸturun (Ã¶nerilir):
   ```bash
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate
   ```

3. Gerekli baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin:
   ```bash
   pip install -r requirements.txt
   ```

4. ffmpeg'i yÃ¼kleyin:
   - **macOS**: `brew install ffmpeg`
   - **Ubuntu/Debian**: `sudo apt-get install ffmpeg`
   - **Windows**: [ffmpeg.org](https://ffmpeg.org/download.html) adresinden indirin ve PATH'e ekleyin

5. API anahtarlarÄ±nÄ± ayarlayÄ±n (isteÄŸe baÄŸlÄ±):
   ```bash
   cp config/api_keys.py.example config/api_keys.py
   ```
   OluÅŸturulan `config/api_keys.py` dosyasÄ±nÄ± dÃ¼zenleyerek kendi API anahtarlarÄ±nÄ±zÄ± ekleyin.

   Alternatif olarak, API anahtarlarÄ±nÄ± Ã§evre deÄŸiÅŸkenleri olarak ayarlayabilirsiniz:
   ```bash
   export OPENAI_API_KEY="sizin_openai_api_anahtarÄ±nÄ±z"
   ```

6. (Ä°steÄŸe baÄŸlÄ±) OpenAI hizmetlerini kullanÄ±yorsanÄ±z `config/settings.py` iÃ§inde API anahtarlarÄ±nÄ± ayarlayÄ±n

## ğŸš€ KullanÄ±m

### Temel KullanÄ±m

UygulamayÄ± bir YouTube URL'si ile Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
python main.py https://www.youtube.com/watch?v=ornek_id
```

### GeliÅŸmiÅŸ SeÃ§enekler

Kaynak ve hedef dilleri belirtin:

```bash
python main.py https://www.youtube.com/watch?v=ornek_id --source en --target tr
```

KullanÄ±labilir parametreler:
- `--source` veya `-s`: Kaynak dil kodu (varsayÄ±lan: en)
- `--target` veya `-t`: Hedef dil kodu (varsayÄ±lan: tr)
- `--tts`: TTS motoru seÃ§eneÄŸi (varsayÄ±lan: gtts, diÄŸer seÃ§enekler: bark, coqui, voice_clone)
- `--reference-audio`: Ses klonlama iÃ§in referans ses dosyasÄ± (voice_clone ile kullanÄ±lÄ±r)
- `--record`: Referans ses kaydÄ± yapmak iÃ§in (voice_clone ile kullanÄ±lÄ±r)
- `--record-duration`: KayÄ±t sÃ¼resi saniye cinsinden (varsayÄ±lan: 10)

## ğŸ§© Proje YapÄ±sÄ±

```
ai_dub/
â”œâ”€â”€ main.py                       # Ana uygulama giriÅŸ noktasÄ±
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py               # YapÄ±landÄ±rma ayarlarÄ±
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ logger.py                 # GÃ¼nlÃ¼k (log) yardÄ±mcÄ± programÄ±
â”‚   â”œâ”€â”€ downloader.py             # YouTube video indirici
â”‚   â”œâ”€â”€ audio_extractor.py        # Videodan ses Ã§Ä±karma
â”‚   â”œâ”€â”€ transcriber.py            # KonuÅŸmadan metne dÃ¶nÃ¼ÅŸtÃ¼rme
â”‚   â”œâ”€â”€ translator.py             # Metin Ã§evirisi
â”‚   â”œâ”€â”€ tts.py                    # Metinden sese dÃ¶nÃ¼ÅŸtÃ¼rme
â”‚   â”œâ”€â”€ voice_cloner.py           # Ses klonlama modÃ¼lÃ¼
â”‚   â””â”€â”€ video_merger.py           # Video ve ses birleÅŸtirme
â”œâ”€â”€ outputs/                      # Ã‡Ä±ktÄ± ve geÃ§ici dosyalar
â”œâ”€â”€ logs/                         # GÃ¼nlÃ¼k dosyalarÄ±
â”œâ”€â”€ requirements.txt              # Proje baÄŸÄ±mlÄ±lÄ±klarÄ±
â””â”€â”€ README.md                     # Proje dokÃ¼mantasyonu
```

## âš™ï¸ Ã–zelleÅŸtirme

`config/settings.py` dosyasÄ±nÄ± dÃ¼zenleyerek uygulamayÄ± Ã¶zelleÅŸtirebilirsiniz:

- VarsayÄ±lan dilleri deÄŸiÅŸtirme
- FarklÄ± TTS motoru seÃ§me
- Model parametrelerini yapÄ±landÄ±rma
- Ã‡Ä±ktÄ± dosya konumlarÄ±nÄ± ayarlama

## ğŸ¤ KatkÄ±da Bulunma

KatkÄ±larÄ±nÄ±zÄ± bekliyoruz! LÃ¼tfen bir Pull Request gÃ¶ndermekten Ã§ekinmeyin.

## ğŸ“œ Lisans

Bu proje aÃ§Ä±k kaynaklÄ±dÄ±r ve [MIT LisansÄ±](LICENSE) altÄ±nda kullanÄ±labilir.

## ğŸ™ TeÅŸekkÃ¼rler

- KonuÅŸma tanÄ±ma kabiliyeti iÃ§in [OpenAI Whisper](https://github.com/openai/whisper)
- Metinden sese dÃ¶nÃ¼ÅŸtÃ¼rme kabiliyetleri iÃ§in [Bark](https://github.com/suno-ai/bark) ve [Coqui TTS](https://github.com/coqui-ai/TTS)
- YouTube indirme iÅŸlevselliÄŸi iÃ§in [pytube](https://github.com/pytube/pytube)
- Ses klonlama iÃ§in [XTTS](https://coqui.ai/blog/tts/xtts-v2-improving-zero-shot-cross-lingual-text-to-speech)
- Yedek metin-konuÅŸma oluÅŸturma iÃ§in [gTTS](https://github.com/pndurette/gTTS)

---

## ğŸ“ Destek

Herhangi bir sorunuz varsa veya sorunlarla karÅŸÄ±laÅŸÄ±rsanÄ±z, lÃ¼tfen bu depoda bir sorun (issue) aÃ§Ä±n.

## ğŸ§‘â€ğŸ’» GeliÅŸtirici

Bu proje [CotNeo](https://github.com/CotNeo) tarafÄ±ndan geliÅŸtirilmiÅŸtir. 

